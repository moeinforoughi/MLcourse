{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lTGGmHBkHL9u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "test_transforms = train_transforms  # same for test\n"
      ],
      "metadata": {
        "id": "PkclZaYEHU8Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(\"data/train\", transform=train_transforms)\n",
        "validation_dataset = datasets.ImageFolder(\"data/test\", transform=test_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=20, shuffle=False)"
      ],
      "metadata": {
        "id": "BA9sYRQLHxTx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HairCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HairCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=0)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        # Calculate the size after conv + pool\n",
        "        # Input: 200x200, kernel=3, padding=0, stride=1 => conv -> 198x198\n",
        "        # After 2x2 pooling -> 99x99\n",
        "        self.fc1 = nn.Linear(32*99*99, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)  # no sigmoid here; use BCEWithLogitsLoss\n",
        "        return x\n",
        "\n",
        "model = HairCNN().to(device)"
      ],
      "metadata": {
        "id": "Tyd5Da7XH8Sh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)"
      ],
      "metadata": {
        "id": "TMag4g5GIAlf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "total_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb1edlrBIDkl",
        "outputId": "d9a0c4b8-01ac-43ca-9e5b-9b74747eb760"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20073473"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)"
      ],
      "metadata": {
        "id": "F6BAI1F_IZW-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "train_acc_list = []\n",
        "train_loss_list = []\n",
        "val_acc_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = correct_train / total_train\n",
        "\n",
        "    train_loss_list.append(epoch_loss)\n",
        "    train_acc_list.append(epoch_acc)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validation_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "\n",
        "    val_loss_list.append(val_epoch_loss)\n",
        "    val_acc_list.append(val_epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/10  Train Acc={epoch_acc:.3f}  Loss={epoch_loss:.3f}  \"\n",
        "          f\"Val Acc={val_epoch_acc:.3f}  Val Loss={val_epoch_loss:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mdDPOedIe1X",
        "outputId": "1f1017f1-b072-471f-bfd0-57698154ef8d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10  Train Acc=0.626  Loss=0.665  Val Acc=0.662  Val Loss=0.610\n",
            "Epoch 2/10  Train Acc=0.709  Loss=0.548  Val Acc=0.647  Val Loss=0.630\n",
            "Epoch 3/10  Train Acc=0.764  Loss=0.486  Val Acc=0.597  Val Loss=0.699\n",
            "Epoch 4/10  Train Acc=0.765  Loss=0.481  Val Acc=0.701  Val Loss=0.610\n",
            "Epoch 5/10  Train Acc=0.786  Loss=0.440  Val Acc=0.652  Val Loss=0.621\n",
            "Epoch 6/10  Train Acc=0.850  Loss=0.349  Val Acc=0.672  Val Loss=0.645\n",
            "Epoch 7/10  Train Acc=0.877  Loss=0.301  Val Acc=0.682  Val Loss=0.695\n",
            "Epoch 8/10  Train Acc=0.894  Loss=0.275  Val Acc=0.721  Val Loss=0.637\n",
            "Epoch 9/10  Train Acc=0.921  Loss=0.211  Val Acc=0.711  Val Loss=0.685\n",
            "Epoch 10/10  Train Acc=0.956  Loss=0.140  Val Acc=0.701  Val Loss=0.812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "median_train_acc = np.median(train_acc_list)\n",
        "median_train_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw0Uh6ETIjUn",
        "outputId": "ab203721-a145-4910-bc4a-a916eaad18a2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.818125)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "std_train_loss = torch.tensor(train_loss_list).std(unbiased=False).item()\n",
        "std_train_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_YtOfJOI9cD",
        "outputId": "9622a8f7-a47c-47c6-bea2-6536116ca242"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15435850620269775"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_aug_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.RandomRotation(50),\n",
        "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "train_dataset_aug = datasets.ImageFolder(\"data/train\", transform=train_aug_transforms)\n",
        "train_loader_aug = DataLoader(train_dataset_aug, batch_size=20, shuffle=True)\n"
      ],
      "metadata": {
        "id": "vlgWA1UjJGWG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_val_losses = []\n",
        "aug_val_accs = []\n",
        "\n",
        "for epoch in range(10):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader_aug:\n",
        "        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validation_loader:\n",
        "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "\n",
        "    aug_val_losses.append(val_epoch_loss)\n",
        "    aug_val_accs.append(val_epoch_acc)\n",
        "\n",
        "    print(f\"[AUG] Epoch {epoch+1}/10  Val Acc={val_epoch_acc:.3f}  Val Loss={val_epoch_loss:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMIo0uTdJodu",
        "outputId": "909c64fe-7d48-4c9b-cca3-f6240a180dcf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUG] Epoch 1/10  Val Acc=0.627  Val Loss=0.751\n",
            "[AUG] Epoch 2/10  Val Acc=0.697  Val Loss=0.570\n",
            "[AUG] Epoch 3/10  Val Acc=0.697  Val Loss=0.592\n",
            "[AUG] Epoch 4/10  Val Acc=0.706  Val Loss=0.556\n",
            "[AUG] Epoch 5/10  Val Acc=0.677  Val Loss=0.581\n",
            "[AUG] Epoch 6/10  Val Acc=0.716  Val Loss=0.511\n",
            "[AUG] Epoch 7/10  Val Acc=0.716  Val Loss=0.569\n",
            "[AUG] Epoch 8/10  Val Acc=0.682  Val Loss=0.594\n",
            "[AUG] Epoch 9/10  Val Acc=0.652  Val Loss=0.692\n",
            "[AUG] Epoch 10/10  Val Acc=0.692  Val Loss=0.549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_aug_val_loss = sum(aug_val_losses) / len(aug_val_losses)\n",
        "mean_aug_val_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h0b3SPbJtXz",
        "outputId": "1fc01efd-9463-4868-c6bb-8b5d6a583480"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.596602615625111"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_last5_acc = sum(aug_val_accs[-5:]) / 5\n",
        "avg_last5_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tin1kw1yKFjI",
        "outputId": "0051ddda-da1c-41f0-8f3d-9c84478c3d46"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.691542288557214"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXUd7iQIKI5I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}